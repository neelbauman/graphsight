# 3. Agentic Architecture with CV Tools

Date: 2026-02-05

## Status

Accepted

## Context

現在の `graphsight` は、画像を一度だけLLMに渡して解析するシングルパスのアプローチを採用している。
しかし、複雑なフローチャートや大規模な図面の場合、一度のパスでは細部の認識漏れや、空間的な配置の誤認（ハルシネーション）が発生しやすい。
LLM単体では、画像の「特定の部分に注目する」「正確な座標を計測する」といった操作ができないことがボトルネックとなっている。

## Decision

以下の2点を決定する。

1. **エージェント指向アーキテクチャへの移行**
   処理フローを直線的な処理から、自律的なループ（Plan -> Think -> Tool -> Evaluate）を持つエージェント型に変更する。
   エージェントは自身でタスクを分解し、段階的にMermaidコードを生成・修正する。

2. **視覚補助ツール（Computer Vision Tools）の導入**
   LLMが画像から客観的な情報を得るためのツールセットを提供する。
   バックエンドには `opencv-python` を使用する。
   提供する主な機能：
   - 画像サイズの計測
   - 画像のリサイズ・クロップ（注目領域の切り出し）
   - エッジ検出（補助的な視覚情報）

## Consequences

### Positive
- 複雑な図面に対する認識精度の向上が期待できる。
- 部分的な修正や再確認が可能になり、頑健性が増す。
- LLMが苦手な空間推論を、決定論的なCVアルゴリズムで補完できる。

### Negative
- 推論にかかる時間とコスト（トークン数）が増加する。
- アーキテクチャが複雑になり、デバッグの難易度が上がる。
- 新たな外部依存 (`opencv-python`) が発生する。

